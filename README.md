
# Tiki Scraper v2 - High Performance Crawler

Há»‡ thá»‘ng crawler hiá»‡u nÄƒng cao Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u sáº£n pháº©m Tiki.

## ðŸš€ TÃ­nh nÄƒng ná»•i báº­t
*   **SiÃªu tá»‘c Ä‘á»™**: Sá»­ dá»¥ng AsyncIO + Aiohttp (20 concurrent requests).
*   **Bá»n bá»‰**: Tá»± Ä‘á»™ng Retry (Backoff) khi máº¡ng lá»—i, tá»± Ä‘á»™ng Resume khi cháº¡y láº¡i.
*   **An toÃ n**: LÆ°u dá»¯ liá»‡u thÃ nh nhiá»u file nhá» Ä‘á»ƒ trÃ¡nh máº¥t mÃ¡t.
*   **Sáº¡ch sáº½**: Code phÃ¢n tÃ¡ch rÃµ rÃ ng (Crawler, Pipeline, Utils), tuÃ¢n thá»§ giao thá»©c Data Engineering.

## ðŸ› ï¸ CÃ i Ä‘áº·t & Sá»­ dá»¥ng

1.  **CÃ i Ä‘áº·t thÆ° viá»‡n:**
    ```bash
    pip install -r requirements.txt
    ```

2.  **Cáº¥u hÃ¬nh:**
    *   Má»Ÿ file `main.py` Ä‘á»ƒ trá» Ä‘Æ°á»ng dáº«n file CSV Ä‘áº§u vÃ o (`INPUT_CSV`).

3.  **Cháº¡y Crawler:**
    ```bash
    python3 main.py
    ```
    Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng quÃ©t vÃ  táº£i dá»¯ liá»‡u vÃ o folder `data/`.

## ðŸ“‚ Cáº¥u trÃºc dá»± Ã¡n
```
.
â”œâ”€â”€ src/                # Source code chÃ­nh
â”‚   â”œâ”€â”€ crawler.py      # Logic call API
â”‚   â”œâ”€â”€ pipeline.py     # Logic Ä‘iá»u phá»‘i luá»“ng
â”‚   â””â”€â”€ utils.py        # HÃ m tiá»‡n Ã­ch
â”œâ”€â”€ data/               # Chá»©a dá»¯ liá»‡u output (JSON)
â”œâ”€â”€ logs/               # Chá»©a log váº­n hÃ nh
â”œâ”€â”€ input/              # Chá»©a file CSV Ä‘áº§u vÃ o
â”œâ”€â”€ main.py             # Entry point
â””â”€â”€ requirements.txt    # Danh sÃ¡ch thÆ° viá»‡n
```

## âš ï¸ LÆ°u Ã½
*   Dá»¯ liá»‡u crawl Ä‘Æ°á»£c (trong folder `data/`) khÃ´ng Ä‘Æ°á»£c upload lÃªn GitHub nÃ y do kÃ­ch thÆ°á»›c lá»›n (>300MB).
*   File log lá»—i náº±m á»Ÿ `logs/error.log`.

---
**Author**: [Nguyen Sy Ha]
